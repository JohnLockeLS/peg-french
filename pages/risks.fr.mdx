# Risques et abus

import { Callout } from 'nextra-theme-docs'

Nous avons déjà vu à quel point des prompts bien conçus peuvent être efficaces pour diverses tâches à l'aide de techniques telles que l'apprentissage few-shot et le chain-of-though prompting. Alors que nous envisageons de construire des applications du monde réel à partir des LLMs, il devient crucial de réfléchir aux abus, aux risques et aux pratiques de sécurité impliqués dans les modèles de langage. 

Cette section se concentre sur la mise en évidence de certains risques et abus des LLMs par le biais de techniques telles que les injections de prompt. Elle met également en évidence les comportements nuisibles et la manière de les atténuer potentiellement grâce à des techniques de prompting efficaces. D'autres sujets d'intérêt incluent la généralisabilité, l'étalonnage, les biais, les biais sociaux et la factualité, pour n'en citer que quelques-uns.

<Callout emoji="⚠️">
  Cette section est en plein développement.
</Callout>
