# Multimodal CoT Prompting

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import MCOT from '../../img/multimodal-cot.png'

[Zhang et al. (2023)](https://arxiv.org/abs/2302.00923) ont récemment proposé une approche multimodale de la chain-of-thought. La CoT traditionnelle se concentre sur la modalité linguistique. En revanche, la CoT multimodale intègre le texte et la vision dans un cadre en deux étapes. La première étape consiste à générer un raisonnement basé sur des informations multimodales. Elle est suivie par la deuxième phase, l'inférence de la réponse, qui exploite les raisonnements informatifs générés.

Le modèle multimodal CoT (1B) surpasse GPT-3.5 sur le benchmark ScienceQA.

<Screenshot src={MCOT} alt="MCOT" />
Image Source: [Zhang et al. (2023)](https://arxiv.org/abs/2302.00923)

Pour en savoir plus :
- [Language Is Not All You Need: Aligning Perception with Language Models](https://arxiv.org/abs/2302.14045) (Feb 2023)
